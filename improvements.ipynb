{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvements after seeing others' Notebooks\n",
    "\n",
    "Inspiration largely from Chong Zhen Jie:\n",
    "- notebook - https://www.kaggle.com/code/chongzhenjie/ecuador-store-sales-global-forecasting-lightgbm/notebook#3.-Model-Training\n",
    "- eda takeaways (not used here)\n",
    "    * missed zero vals (leading, trailing 0s, number of 0s)\n",
    "    * holidays (filtering for region, work days, etc.)\n",
    "    * store clustering\n",
    "\n",
    "- modelling takeaways\n",
    "    * interpolate missing dates (like jan. 01, christmas)\n",
    "    * dif model for each family\n",
    "    * different samples of training data --> ensemble models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the main improvements I can make?\n",
    "\n",
    "- features\n",
    "    * oil, oil rolling\n",
    "    * transactions\n",
    "    * store cluster, type, etc.\n",
    "\n",
    "    * holidays merged (city, state, national, work) - or maybe we can delete holidays\n",
    "\n",
    "- modelling\n",
    "    * train dif model per family\n",
    "    * zero out predictions if there are some # of trailing 0s\n",
    "    * train models on dif train periods (can also exclude before 2015), then ensemble\n",
    "    * try weighted lgbm highlighting end of aug (own idea, not sure if itll help at all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import root_mean_squared_log_error, root_mean_squared_error, mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from itertools import product\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv', parse_dates=['date']).drop(columns='id')\n",
    "test_df = pd.read_csv('data/test.csv', parse_dates=['date']).drop(columns='id')\n",
    "transactions_df = pd.read_csv('data/transactions.csv', parse_dates=['date'])\n",
    "oil_df = pd.read_csv('data/oil.csv', parse_dates=['date'])\n",
    "holidays_df = pd.read_csv('data/holidays_events.csv', parse_dates=['date'])\n",
    "stores_df = pd.read_csv('data/stores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing (fix missing vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days in Oil Range: 2013-01-01 to 2017-08-31, 1704 days\n",
      "Days in Actual oil df: 1218\n",
      "After interpolating, 0 missing values\n"
     ]
    }
   ],
   "source": [
    "# Fix missing dates / NaNs in oil df\n",
    "start_day = oil_df['date'].min()\n",
    "end_day = oil_df['date'].max()\n",
    "date_range = pd.date_range(start_day, end_day)\n",
    "print(f\"Days in Oil Range: {start_day.strftime('%Y-%m-%d')} to {end_day.strftime('%Y-%m-%d')}, {len(date_range)} days\")\n",
    "print(f\"Days in Actual oil df: {len(oil_df['date'])}\")\n",
    "\n",
    "oil_all_days = oil_df.merge(pd.DataFrame({'date': date_range}), how='outer', on='date')\n",
    "interpolated_oil = oil_all_days.interpolate(method='linear', limit_direction='both')\n",
    "print(f\"After interpolating, {interpolated_oil.isna().sum().sum()} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train # Days: 1684\n",
      "# Holidays: 312\n",
      "Leftover days: 1432\n"
     ]
    }
   ],
   "source": [
    "# Delete all holidays in train\n",
    "print(\"Train # Days:\", len(train_df['date'].unique()))\n",
    "print(\"# Holidays:\", len(holidays_df['date'].unique()))\n",
    "\n",
    "holidays_removed = train_df[~train_df['date'].isin(holidays_df['date'])]\n",
    "holidays_removed.isna().sum()\n",
    "\n",
    "print(\"Leftover days:\", len(holidays_removed['date'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days in train: 1432\n",
      "Stores in train: 54\n",
      "Expected # transactions: 77328\n",
      "Len Transactions: 71096\n",
      "Stores w/ 0 sales in train: 6115\n",
      "Not zero missing in transactions (unexpected): 117\n",
      "\n",
      "Before na: 6232\n",
      "Zero sales: 6115\n",
      "Remaining na: 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_c/j62lsd3n7x9_vq272kdsl3fc0000gn/T/ipykernel_43273/4119929746.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  final_transactions = all_transactions.groupby(by='store_nbr', group_keys=False).apply(lambda col : col.interpolate(method='linear')).sort_values(by=['date', 'store_nbr'])\n"
     ]
    }
   ],
   "source": [
    "# Fix transactions df\n",
    "filtered_transactions = transactions_df[transactions_df['date'].isin(holidays_removed['date'])]\n",
    "\n",
    "num_days = len(holidays_removed['date'].unique())\n",
    "num_stores = len(holidays_removed['store_nbr'].unique())\n",
    "print(\"Days in train:\", num_days)\n",
    "print(\"Stores in train:\", num_stores)\n",
    "print(\"Expected # transactions:\", num_days * num_stores)\n",
    "print(\"Len Transactions:\", len(filtered_transactions))\n",
    "\n",
    "train_zero_sales = (holidays_removed.groupby(by=['date', 'store_nbr'])['sales'].sum() == 0).sum()\n",
    "print(\"Stores w/ 0 sales in train:\", train_zero_sales)\n",
    "print(\"Not zero missing in transactions (unexpected):\", num_days * num_stores - len(filtered_transactions) - train_zero_sales)\n",
    "print()\n",
    "\n",
    "# other way of getting days where a store had zero sales\n",
    "# store_pivot = holidays_removed.pivot_table(index='date', columns='store_nbr', values='sales', aggfunc='sum')\n",
    "# (store_pivot == 0).sum().sum()\n",
    "\n",
    "zero_sales = (holidays_removed.groupby(by=['date', 'store_nbr'])['sales'].sum() == 0).to_frame('zero_sales').reset_index()\n",
    "zero_sales\n",
    "\n",
    "# Make transactions df have all days; some 0\n",
    "all_days = pd.DataFrame(product(holidays_removed['date'].unique(), holidays_removed['store_nbr'].unique()), columns=['date', 'store_nbr'])\n",
    "all_transactions = filtered_transactions.merge(all_days, on=['date', 'store_nbr'], how='outer')\n",
    "print(\"Before na:\", all_transactions.isna().sum().sum())\n",
    "print(\"Zero sales:\", len(zero_sales[zero_sales['zero_sales'] == True]))\n",
    "all_transactions.loc[zero_sales['zero_sales'] == True,'transactions'] = 0\n",
    "print(\"Remaining na:\", all_transactions.isna().sum().sum())\n",
    "\n",
    "# Fill the other NA Values with interpolation (b/c of graphs below)\n",
    "final_transactions = all_transactions.groupby(by='store_nbr', group_keys=False).apply(lambda col : col.interpolate(method='linear')).sort_values(by=['date', 'store_nbr'])\n",
    "\n",
    "# Check the other transactions\n",
    "# why_nan = all_transactions[all_transactions.isna().sum(axis=1).astype(bool)].copy()\n",
    "# why_nan['transactions'] = 1\n",
    "\n",
    "# viz_transactions = holidays_removed.merge(why_nan, on=['date', 'store_nbr'], how='left')\n",
    "# viz_transactions = viz_transactions.fillna(0)\n",
    "\n",
    "# avg_sales = viz_transactions.groupby(by=['store_nbr', 'family', 'transactions'])['sales'].mean().to_frame('mean_sales').reset_index()\n",
    "# avg_sales['mean_sales'] = np.log1p(avg_sales['mean_sales'])\n",
    "# sns.boxplot(data=avg_sales, x='family', y='mean_sales', hue='transactions')\n",
    "# plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "What features do I add:\n",
    "    1. oil\n",
    "    2. transactions\n",
    "    3. onpromotion\n",
    "    rolling for all of the above\n",
    "\"\"\"\n",
    "\n",
    "combined = holidays_removed.copy()\n",
    "combined = combined.merge(right=stores_df, on='store_nbr', how='left') \\\n",
    "                    .merge(right=interpolated_oil, on='date', how='left') \\\n",
    "                    .merge(right=final_transactions, on=['date', 'store_nbr'], how='left')\n",
    "\n",
    "combined['sales'] = np.log1p(combined['sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING\n",
    "def lag_store_fam(df, time=pd.Timedelta(days=7)):\n",
    "    curr_df = df.copy()\n",
    "\n",
    "    shift_df = df[['date', 'sales', 'store_nbr', 'family']].copy()\n",
    "    shift_df['date'] = shift_df['date'] + time\n",
    "    shift_df = shift_df.rename(columns={'sales': 'shift_sales'})\n",
    "\n",
    "    lag_df = pd.merge_asof(left=curr_df, right=shift_df, on='date', by=['store_nbr', 'family'], direction='backward')\n",
    "    return lag_df.dropna(axis=0)\n",
    "\n",
    "def date_features(df):\n",
    "    curr_df = df.copy()\n",
    "    curr_df['day_of_week'] = df['date'].dt.day_of_week\n",
    "    curr_df['day_of_year'] = df['date'].dt.day_of_year\n",
    "    curr_df['day_of_month'] = df['date'].dt.day\n",
    "    curr_df['month'] = df['date'].dt.month\n",
    "    return curr_df\n",
    "\n",
    "def encode(df):\n",
    "    curr_df = df.copy()\n",
    "    for col in curr_df.select_dtypes(include='object').columns.difference(['date']):\n",
    "        curr_df[col], _ = pd.factorize(curr_df[col])\n",
    "    return curr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = lag_store_fam(combined)\n",
    "fe = date_features(fe)\n",
    "fe = encode(fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = fe.drop(columns=['city', 'state', 'type', 'cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>transactions</th>\n",
       "      <th>shift_sales</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10692</th>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0</td>\n",
       "      <td>93.08</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10693</th>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>93.08</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10694</th>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "      <td>93.08</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10695</th>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.079184</td>\n",
       "      <td>0</td>\n",
       "      <td>93.08</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>6.995766</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10696</th>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>93.08</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551819</th>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>5.650484</td>\n",
       "      <td>0</td>\n",
       "      <td>47.59</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>6.131313</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551820</th>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>4.745975</td>\n",
       "      <td>0</td>\n",
       "      <td>47.59</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>4.794964</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551821</th>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>7.207434</td>\n",
       "      <td>7</td>\n",
       "      <td>47.59</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>7.424220</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551822</th>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>5.209486</td>\n",
       "      <td>11</td>\n",
       "      <td>47.59</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>4.990433</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551823</th>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>2.890372</td>\n",
       "      <td>0</td>\n",
       "      <td>47.59</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>3.204087</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2541132 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  store_nbr  family     sales  onpromotion  dcoilwtico  \\\n",
       "10692   2013-01-09          1       0  1.098612            0       93.08   \n",
       "10693   2013-01-09          1       1  0.000000            0       93.08   \n",
       "10694   2013-01-09          1       2  0.693147            0       93.08   \n",
       "10695   2013-01-09          1       3  7.079184            0       93.08   \n",
       "10696   2013-01-09          1       4  0.000000            0       93.08   \n",
       "...            ...        ...     ...       ...          ...         ...   \n",
       "2551819 2017-08-14          9      28  5.650484            0       47.59   \n",
       "2551820 2017-08-14          9      29  4.745975            0       47.59   \n",
       "2551821 2017-08-14          9      30  7.207434            7       47.59   \n",
       "2551822 2017-08-14          9      31  5.209486           11       47.59   \n",
       "2551823 2017-08-14          9      32  2.890372            0       47.59   \n",
       "\n",
       "         transactions  shift_sales  day_of_week  day_of_year  day_of_month  \\\n",
       "10692          1910.0     1.098612            2            9             9   \n",
       "10693          1910.0     0.000000            2            9             9   \n",
       "10694          1910.0     1.098612            2            9             9   \n",
       "10695          1910.0     6.995766            2            9             9   \n",
       "10696          1910.0     0.000000            2            9             9   \n",
       "...               ...          ...          ...          ...           ...   \n",
       "2551819        1971.0     6.131313            0          226            14   \n",
       "2551820        1971.0     4.794964            0          226            14   \n",
       "2551821        1971.0     7.424220            0          226            14   \n",
       "2551822        1971.0     4.990433            0          226            14   \n",
       "2551823        1971.0     3.204087            0          226            14   \n",
       "\n",
       "         month  \n",
       "10692        1  \n",
       "10693        1  \n",
       "10694        1  \n",
       "10695        1  \n",
       "10696        1  \n",
       "...        ...  \n",
       "2551819      8  \n",
       "2551820      8  \n",
       "2551821      8  \n",
       "2551822      8  \n",
       "2551823      8  \n",
       "\n",
       "[2541132 rows x 12 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.52874\n",
      "1 : 0.32149\n",
      "2 : 0.50266\n",
      "3 : 0.26546\n",
      "4 : 0.45152\n",
      "5 : 0.17145\n",
      "6 : 0.66502\n",
      "7 : 0.22863\n",
      "8 : 0.15759\n",
      "9 : 0.18213\n",
      "10 : 0.32186\n",
      "11 : 0.30083\n",
      "12 : 0.16269\n",
      "13 : 0.60522\n",
      "14 : 0.55827\n",
      "15 : 0.57182\n",
      "16 : 0.46318\n",
      "17 : 0.41880\n",
      "18 : 0.44064\n",
      "19 : 0.59280\n",
      "20 : 0.76844\n",
      "21 : 0.66555\n",
      "22 : 0.92300\n",
      "23 : 0.69411\n",
      "24 : 0.22974\n",
      "25 : 0.22101\n",
      "26 : 0.67603\n",
      "27 : 0.66746\n",
      "28 : 0.22781\n",
      "29 : 0.32445\n",
      "30 : 0.64780\n",
      "31 : 0.66769\n",
      "32 : 0.52324\n",
      "Final Error: 0.50213\n"
     ]
    }
   ],
   "source": [
    "model = HistGradientBoostingRegressor()\n",
    "\n",
    "mean_squared_errors = []\n",
    "for family in fe['family'].unique():\n",
    "    filtered = fe[fe['family'] == family].drop(columns='family')\n",
    "\n",
    "    train = filtered[filtered['date'] < '2017-01-01'].drop(columns='date')\n",
    "    test = filtered[filtered['date'] >= '2017-01-01'].drop(columns='date')\n",
    "\n",
    "    X_train, y_train = train.drop(columns='sales'), train['sales']\n",
    "    X_test, y_test = test.drop(columns='sales'), test['sales']\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    rmse = root_mean_squared_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mean_squared_errors.append(mse)\n",
    "\n",
    "    print(family, f': {rmse:.5f}')\n",
    "\n",
    "error = np.sqrt(np.mean(mean_squared_errors))\n",
    "print(f'Final Error: {error:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tradingClub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
